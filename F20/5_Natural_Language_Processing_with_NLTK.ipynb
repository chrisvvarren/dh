{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE: Colored Convention Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './ccp_all.txt'\n",
    "\n",
    "with codecs.open(filename, 'rU', 'utf-8') as f:  #'rU\" strips newlines\n",
    "    file = f.read()\n",
    "    file.strip()\n",
    "    sentences = sent_tokenize(file)\n",
    "    words = word_tokenize(file)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in words if len(word) > 2]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in words if not word in stop_words]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word.lower() for word in words]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(words)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [word for word in words if word.isnumeric()]\n",
    "fdist_num = nltk.FreqDist(numbers)\n",
    "fdist_num.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [number for number in numbers if len(number) >= 4]\n",
    "fdist_num = nltk.FreqDist(numbers)\n",
    "fdist_num.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_cleaner(filename):\n",
    "    clean_name = re.match((\"(.*)(.txt)\"), filename)\n",
    "    clean_name = clean_name.group(1).strip('../')\n",
    "    return clean_name\n",
    "\n",
    "def nltk_ops(filename):\n",
    "\n",
    "    clean_name = name_cleaner(filename)\n",
    "    with codecs.open(filename, 'rU', 'utf-8') as f:  #'rU\" strips newlines\n",
    "        file = f.read()\n",
    "        file.strip()\n",
    "        sentences = sent_tokenize(file)\n",
    "        words = word_tokenize(file)\n",
    "        words = [word for word in words if len(word) > 2]\n",
    "        words = [word for word in words if not word in stop_words]\n",
    "        for sentence in sentences:\n",
    "            sentence_words = word_tokenize(sentence)      \n",
    "\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    fdist = nltk.FreqDist(words)\n",
    "    with open(\"%s_most_common_words.txt\" % clean_name, \"w\") as outfile: \n",
    "        for word, frequency in fdist.most_common(50):\n",
    "            frequency = str(frequency)\n",
    "            outfile.write(\"{}\\t{}\\n\".format(word,frequency))\n",
    "        \n",
    "    numbers = [word for word in words if word.isnumeric()]\n",
    "    numbers = [number for number in numbers if len(number) >= 4]\n",
    "    fdist_num = nltk.FreqDist(numbers)\n",
    "    with open(\"%s_most_common_numbers.txt\" % clean_name, \"w\") as outfile: \n",
    "        for word, frequency in fdist_num.most_common(50):\n",
    "            frequency = str(frequency)\n",
    "            outfile.write(\"{}\\t{}\\n\".format(word,frequency))\n",
    "\n",
    "    sentences = [sentence for sentence in sentences if len(sentence) > 15]\n",
    "    fdist_sent = nltk.FreqDist(sentences)\n",
    "    with open(\"%s_most_common_sentences.txt\" % clean_name, \"w\") as outfile: \n",
    "        for sentence, frequency in fdist_sent.most_common(50):\n",
    "           outfile.write(\"{}\\t{}\\n\".format(sentence,frequency))\n",
    "    \n",
    "    data = [fdist,fdist_num,fdist_sent]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp = nltk_ops(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dist in ccp:\n",
    "    print(dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(ccp[1])\n",
    "years = pd.Series(fdist)\n",
    "years = years.sort_index(ascending=True).reset_index().rename(columns={'index': 'Year', 0: 'Count'})\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years['Year'] = pd.to_numeric(years['Year'])\n",
    "data = years.loc[years['Year'].between(1800,1940)]\n",
    "data = data.set_index('Year')\n",
    "#data.rename(columns={'index':'Year', '0':'Count'}, inplace=True)\n",
    "fig, ax = plt.subplots(figsize=[20,4])\n",
    "fig.suptitle('Frequency of Years Mentioned in  Text', fontweight='bold')\n",
    "data.plot(color='cornflowerblue', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's Try It With Tolstoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolstoy = nltk_ops('./tolstoy.txt')\n",
    "for dist in tolstoy:\n",
    "    print(dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
